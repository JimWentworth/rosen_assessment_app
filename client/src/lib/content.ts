export interface TabContent {
  id: string;
  number?: number;
  title: string;
  subtitle?: string;
  sections: Section[];
}

export interface Section {
  heading: string;
  content: string[];
  isCallout?: boolean;
}

export const assessmentModels: TabContent[] = [
  {
    id: "case-formulation",
    number: 1,
    title: "AI-Assisted Case Formulation with Required Clinical Justification",
    subtitle: "From abstract theory comparison → applied diagnostic reasoning",
    sections: [
      {
        heading: "Core Shift",
        content: [
          "Students move from comparing abstract theories to applying diagnostic reasoning in real clinical contexts."
        ]
      },
      {
        heading: "Assignment Structure",
        content: [
          "Students are given a detailed client case (history, symptoms, context, contradictory clues). They may use AI as a 'consultation assistant,' but must submit:",
          "• Their diagnostic formulation",
          "• Their reasoning process (which symptoms matter and why)",
          "• A comparison of at least two theoretical interpretations",
          "• A transcript showing how they used AI",
          "• A critique of AI's suggestions (what it missed, oversimplified, or got wrong)"
        ]
      },
      {
        heading: "Why This Works",
        content: [
          "In counseling practice, clinicians consult tools and colleagues—AI becomes analogous to that. Students must demonstrate judgment, not just output. AI use becomes visible and assessable rather than hidden."
        ],
        isCallout: true
      },
      {
        heading: "What You Assess",
        content: [
          "• Clinical reasoning quality",
          "• Ability to evaluate AI output critically",
          "• Integration of theory and evidence",
          "\nThis makes unauthorized AI use irrelevant because the assignment requires documented, evaluated AI use."
        ]
      }
    ]
  },
  {
    id: "flawed-diagnosis",
    number: 2,
    title: "AI-Generated 'Flawed Diagnosis' Critique",
    subtitle: "From producing content → evaluating content",
    sections: [
      {
        heading: "Core Shift",
        content: [
          "Students shift from generating content to evaluating and critiquing content—a higher-order cognitive skill."
        ]
      },
      {
        heading: "Assignment Structure",
        content: [
          "Students receive a diagnostic report generated by AI that contains subtle conceptual errors, omissions, or misinterpretations. Their task:",
          "• Identify errors or oversimplifications",
          "• Explain why each is incorrect",
          "• Correct the diagnosis using DSM-consistent reasoning",
          "• Explain which theoretical perspective better accounts for the disorder"
        ]
      },
      {
        heading: "Why This Works",
        content: [
          "Evaluating reasoning requires deeper expertise than generating summaries. AI is very good at producing plausible but imperfect clinical reasoning—this becomes a teaching tool. Students cannot simply submit AI output because the assignment requires detecting AI's mistakes. This directly builds clinical skepticism, a core professional skill."
        ],
        isCallout: true
      }
    ]
  },
  {
    id: "longitudinal-tracking",
    number: 3,
    title: "Longitudinal AI-Supported Case Tracking (Progressive Disclosure Model)",
    subtitle: "From one-shot papers → developmental reasoning over time",
    sections: [
      {
        heading: "Core Shift",
        content: [
          "Students follow the same fictional client over several weeks, revising their understanding as new information emerges—mirroring real clinical practice."
        ]
      },
      {
        heading: "Assignment Structure",
        content: [
          "Over several weeks, students follow the same fictional client. New information is released periodically:",
          "• Week 1: Initial intake summary",
          "• Week 3: New symptoms emerge",
          "• Week 5: Social and family history revealed",
          "• Week 7: Treatment response data",
          "\nStudents may use AI to help interpret each stage, but must revise their diagnostic hypotheses. Final submission includes:",
          "• Evolution of their diagnosis",
          "• Explanation of changes",
          "• Reflection on uncertainty and ambiguity",
          "• Explanation of where AI helped and where it misled them"
        ]
      },
      {
        heading: "Why This Works",
        content: [
          "This models real clinical practice, where diagnosis evolves. It also builds durable learning through repeated retrieval and application, directly addressing the retention problem. Students engage with the same case multiple times, strengthening schema formation."
        ],
        isCallout: true
      }
    ]
  },
  {
    id: "oral-defense",
    number: 4,
    title: "AI-Supported Oral Defense (Scalable Micro-Viva via Recorded Video)",
    subtitle: "From anonymous written output → accountable reasoning",
    sections: [
      {
        heading: "Core Shift",
        content: [
          "Students move from anonymous written submissions to recorded explanations of their reasoning, creating accountability and demonstrating understanding."
        ]
      },
      {
        heading: "Assignment Structure",
        content: [
          "Students submit a brief diagnostic analysis, then record a 5-minute oral defense answering prompts such as:",
          "• Why did you prioritize these symptoms?",
          "• Why did you reject alternative diagnoses?",
          "• What would change your mind?",
          "• How did AI influence your thinking?",
          "\nAI can be used in preparation, but the oral explanation must reflect personal understanding."
        ]
      },
      {
        heading: "Scaling Approach",
        content: [
          "This can be scaled using:",
          "• Recorded video submissions",
          "• Structured rubric grading",
          "• Random sampling for deeper review",
          "\nAI cannot convincingly replace spontaneous explanation of reasoning without preparation and understanding. This restores epistemic accountability."
        ],
        isCallout: true
      }
    ]
  },
  {
    id: "simulated-client",
    number: 5,
    title: "AI as Simulated Client: Interview and Interpretation Assignment",
    subtitle: "From passive memorization → active information gathering",
    sections: [
      {
        heading: "Core Shift",
        content: [
          "Students shift from passive reading to active clinical interviewing, gathering information through appropriate questioning."
        ]
      },
      {
        heading: "Assignment Structure",
        content: [
          "Students interact with a structured AI 'client' simulation that reveals information only when asked appropriate clinical questions. Students submit:",
          "• Their interview questions",
          "• Transcript of interaction",
          "• Diagnostic conclusion",
          "• Explanation of why they asked specific questions"
        ]
      },
      {
        heading: "Assessment Focus",
        content: [
          "Assessment focuses on:",
          "• Quality of questions",
          "• Ability to gather relevant information",
          "• Diagnostic reasoning",
          "\nThis evaluates actual clinical thinking, not memorization. It also scales well because AI handles interaction."
        ],
        isCallout: true
      }
    ]
  },
  {
    id: "collaborative-consensus",
    number: 6,
    title: "Collaborative Human-AI Diagnostic Consensus Exercise",
    subtitle: "From individual static papers → collaborative evaluation of AI reasoning",
    sections: [
      {
        heading: "Core Shift",
        content: [
          "Students work collaboratively, first reasoning independently, then consulting AI, then revising—building metacognitive awareness of AI's role."
        ]
      },
      {
        heading: "Assignment Structure",
        content: [
          "Students work in small groups. Each group:",
          "• Receives a case",
          "• Generates an initial diagnosis without AI",
          "• Then consults AI",
          "• Then revises their diagnosis",
          "\nThey submit a structured report documenting:",
          "• Their original reasoning",
          "• How AI changed their thinking",
          "• Where AI helped",
          "• Where AI was wrong"
        ]
      },
      {
        heading: "Why This Works",
        content: [
          "This teaches metacognition, appropriate reliance on AI, and limits of AI systems. It is especially effective in large lecture courses because groups reduce grading load while maintaining individual accountability through structured reflection."
        ],
        isCallout: true
      }
    ]
  }
];

export const synthesisTab: TabContent = {
  id: "synthesis",
  title: "Why These Approaches Solve Dr. Rosen's Three Core Problems",
  sections: [
    {
      heading: "Problem 1: Students Forget Content",
      content: [
        "Traditional lecture-based learning often results in isolated facts that fade quickly from memory. Students memorize definitions and theories for exams, then forget them weeks later.",
        "\nSolution: Repeated case-based reasoning builds durable schemas rather than isolated facts.",
        "\nEach of the six approaches uses spaced retrieval and elaboration—students encounter the same diagnostic concepts repeatedly across different cases and contexts. Longitudinal case tracking (Model 3) explicitly builds this through progressive disclosure. When students must apply theory to practice multiple times, they develop integrated mental models that persist."
      ],
      isCallout: true
    },
    {
      heading: "Problem 2: AI-Generated Papers",
      content: [
        "When students can submit AI-generated output directly, assessment becomes meaningless. The assignment no longer measures student learning—it measures AI capability.",
        "\nSolution: Assignments require reasoning transparency, critique, and interaction—not just output.",
        "\nAll six models make AI use visible and evaluable. Students must justify their reasoning (Model 1), critique AI's mistakes (Model 2), explain their evolving thinking (Model 3), defend their conclusions orally (Model 4), demonstrate question quality (Model 5), and reflect on AI's role (Model 6). None of these can be credibly faked. A student cannot submit an AI-generated oral defense or fabricate a transcript of their own clinical interviewing."
      ],
      isCallout: true
    },
    {
      heading: "Problem 3: Scaling to 90 Students",
      content: [
        "Traditional grading of 90 individual papers is unsustainable. Faculty cannot provide meaningful feedback at scale, and students receive generic comments.",
        "\nSolution: Structured templates, AI-supported simulations, group work, and recorded oral defenses scale without requiring proportional grading increases.",
        "\nModel 1 and 2 use structured rubrics that accelerate grading. Model 3 uses progressive disclosure (same case, multiple submissions) rather than 90 unique cases. Model 4 uses random sampling—grade 30 oral defenses deeply rather than 90 papers superficially. Model 5 uses AI as the interaction partner, eliminating the need for faculty-student interviews. Model 6 uses group work, reducing grading load by 75% while maintaining accountability through structured reflection."
      ],
      isCallout: true
    },
    {
      heading: "Critical Design Principle: Shift from 'What do you know?' to 'How do you think?'",
      content: [
        "Traditional assessment asks students to reproduce information: 'Define major depressive disorder.' 'List the DSM-5 criteria.' 'Describe cognitive-behavioral theory.'",
        "\nBut AI can reproduce information. It cannot reliably reproduce situated judgment, critique, and evolving reasoning unless the student possesses those abilities.",
        "\nAll six models assess the competencies that matter in practice:"
      ]
    },
    {
      heading: "Authentic Assessment in This Domain Evaluates:",
      content: [
        "• Diagnostic reasoning: Can the student identify relevant symptoms and construct a coherent clinical narrative?",
        "• Theory application: Can the student select appropriate theoretical frameworks and explain why they fit?",
        "• Uncertainty management: Can the student acknowledge ambiguity, revise hypotheses, and explain what would change their mind?",
        "• Critical evaluation of tools (including AI): Can the student identify limitations, detect errors, and use AI appropriately?",
        "\nThese are exactly the competencies counseling psychologists and social workers need. They are also the competencies that cannot be outsourced to AI—they require human judgment, reflection, and professional accountability."
      ]
    },
    {
      heading: "Implementation Readiness",
      content: [
        "Each of these six approaches can be translated into concrete assignment prompts and grading rubrics appropriate for an undergraduate abnormal psychology course. The models are not theoretical—they are immediately actionable.",
        "\nThey work together as a portfolio of assessment strategies, allowing you to select the approaches that best fit your course structure, student population, and learning objectives. Some instructors may use all six across a semester; others may focus on two or three that align most closely with their pedagogical goals.",
        "\nThe common thread: all six shift assessment from 'What do you know?' to 'How do you think?'—and in doing so, they make AI use transparent, learning durable, and scaling feasible."
      ]
    }
  ]
};
